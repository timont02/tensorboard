{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some simple overview over the Data and other stuff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self labeled images taken by Timo Trautwein with a smartphone: 384\n",
    "\n",
    "Self labeled images from the internet: 44\n",
    "\n",
    "Additional already labeled images from [https://www.kaggle.com/datasets/andrewmvd/tomato-detection?select=images](kaggle): 895"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Total count for Training and Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images taken to train: 197\n",
      "Images taken to evaluate the training: 0\n",
      "Images taken to test: 92\n",
      "Total image count: 289\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "TRAINSET_PATH = os.path.join('../Tensorflow', 'workspace', 'images', 'trainset')\n",
    "TESTSET_PATH = os.path.join('../Tensorflow', 'workspace', 'images', 'testset')\n",
    "DEVSET_PATH = os.path.join('../Tensorflow', 'workspace', 'images', 'devset')\n",
    "\n",
    "trainset_length = len(glob.glob1(TRAINSET_PATH,\"*.jpg\"))\n",
    "testset_length = len(glob.glob1(TESTSET_PATH,\"*.jpg\"))\n",
    "devset_length = len(glob.glob1(DEVSET_PATH,\"*.jpg\"))\n",
    "\n",
    "print(\"Images taken to train: {}\".format(trainset_length))\n",
    "\n",
    "print(\"Images taken to evaluate the training: {}\".format(devset_length))\n",
    "\n",
    "print(\"Images taken to test: {}\".format(testset_length))\n",
    "\n",
    "print(\"Total image count: {}\".format(testset_length + trainset_length + devset_length))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this given input we have some labeled Data as of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels taken to train: {'RipeTomato': 3606, 'UnripeTomato': 3628}\n",
      "Labels taken to evaluate: {'RipeTomato': 0, 'UnripeTomato': 0}\n",
      "Labels taken to test: {'RipeTomato': 514, 'UnripeTomato': 1226}\n",
      "Total label count: {'RipeTomato': 4120, 'UnripeTomato': 4854}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "labels = {'RipeTomato': 0, 'UnripeTomato': 0}\n",
    "\n",
    "\n",
    "trainset_labels = labels.copy()\n",
    "testset_labels = labels.copy()\n",
    "devset_labels = labels.copy()\n",
    "\n",
    "files = Path(TRAINSET_PATH).glob('*.xml')\n",
    "\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        content = f.read()\n",
    "        for label_name in trainset_labels.keys():\n",
    "            trainset_labels[label_name] += sum(1 for match in re.finditer(r\"\\b{}\\b\".format(label_name), content))\n",
    "\n",
    "files = Path(TESTSET_PATH).glob('*.xml')\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        content = f.read()\n",
    "        for label_name in testset_labels.keys():\n",
    "            testset_labels[label_name] += sum(1 for match in re.finditer(r\"\\b{}\\b\".format(label_name), content))\n",
    "\n",
    "files = Path(DEVSET_PATH).glob('*.xml')\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        content = f.read()\n",
    "        for label_name in devset_labels.keys():\n",
    "            devset_labels[label_name] += sum(1 for match in re.finditer(r\"\\b{}\\b\".format(label_name), content))\n",
    "\n",
    "for label_name in labels.keys():\n",
    "    labels[label_name] += trainset_labels[label_name] + testset_labels[label_name] + devset_labels[label_name]\n",
    "\n",
    "print(\"Labels taken to train: {}\".format(trainset_labels))\n",
    "print(\"Labels taken to evaluate: {}\".format(devset_labels))\n",
    "print(\"Labels taken to test: {}\".format(testset_labels))\n",
    "print(\"Total label count: {}\".format(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TomatoCounter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e6b86ef769d7ca855e44f0cec3602c343199247f1fa527b4b97d028d34d1df0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
